{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7d29fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THE PATH TO THE PATH AT YOUR PC!\n",
    "path = \"C:\\\\Users\\\\user\\\\Desktop\\\\TUe\\\\Topological\\\\Project\\\\Geolife Trajectories 1.3\\\\Data\\\\\"\n",
    "#path = \"Geolife Trajectories 1.3\\\\Data\\\\\"\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698ce44b",
   "metadata": {},
   "source": [
    "## Changes in the processing:\n",
    "\n",
    "- Date converted to datetime format and to Beijing time (for day/night purposes)\n",
    "\n",
    "- Feet altitude converted to meters, because we have any remains of self-respect\n",
    "\n",
    "- Plug in the path from above and one number - the number of person as given by the folders\n",
    "\n",
    "- Creates one full.csv dataset for one person outside the redundant Trajectories folder\n",
    "\n",
    "- Prunes it so that no trajectory datapoint is recorded if no movement was detected\n",
    "\n",
    "- ^No such case found in the first couple files, lol. So this will not run on the dataset\n",
    "\n",
    "- ^Perhaps we shall just set a threshold there, so that movement of speed 1 meter per hour (if exists) is trated as no movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2920dbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_date(row):\n",
    "    '''Merges the date and time, converts them into datetime objects\n",
    "    And converts into Beijing time [by adding 8 hours to the UTC, idc about winter/summer time]'''\n",
    "    \n",
    "    text1, text2 = row['date'], row['hour']\n",
    "    text1 = text1+'&'+text2\n",
    "    time = datetime.strptime(text1, '%Y-%m-%d&%H:%M:%S') + timedelta(hours=8)\n",
    "    return time\n",
    "\n",
    "def feet_to_meters(text: str):\n",
    "    '''because we use metric system here'''\n",
    "    return round(int(text)/3.28084)\n",
    "\n",
    "def data_per_file(path, prune_redundant=False):\n",
    "    '''Altitude set to -237 if None\n",
    "    DataFramifies one .plt trajectory file\n",
    "    latitude NORTH, longitude EAST, altitude METERS\n",
    "    prune_redundant for now did not prune a single row, which is disturbing'''\n",
    "    \n",
    "    #Reading the dataset and removing redundant columns:\n",
    "    df = pd.read_csv(path, skiprows=6)\n",
    "    df.columns = ['latitude', 'longitude', 'worthless1', 'altitude', 'worthless2', 'date', 'hour']\n",
    "    df = df.drop(['worthless1', 'worthless2'], axis=1)\n",
    "    \n",
    "    #Simplifying the date format and chaning to local time:\n",
    "    df['full_date'] = df.apply(fix_date, axis=1)\n",
    "    df = df.drop(['date', 'hour'], axis=1)\n",
    "    df.columns = list(df.columns[:-1]) + [\"date\"]\n",
    "    \n",
    "    #(possibly) pruning the useless (no movement) rows:\n",
    "    if prune_redundant:\n",
    "        to_be_deleted_rows = delete_redundant_rows(df)\n",
    "        df = df.drop(to_be_deleted_rows, axis=1).reset_index(drop=True)\n",
    "    \n",
    "    #Converting feet to meters\n",
    "    df['altitude'] = df['altitude'].apply(feet_to_meters)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def save_data_per_person(path: str, number_person_as_string: str):\n",
    "    '''Runs the data_per_file once for each file one person has and concatenates the result'''\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for element in os.listdir(path + number_person_as_string + \"\\\\Trajectory\"):\n",
    "        file_path = path + number_person_as_string + \"\\\\Trajectory\\\\\" + element\n",
    "        download_df = data_per_file(file_path)\n",
    "        download_df[\"trajectory\"] = number_person_as_string + \".\" + element[:-4]\n",
    "        df = pd.concat([df, download_df], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    df[\"user\"] = number_person_as_string\n",
    "    \n",
    "    #Saved as a CSV outside the redundant Trajectories folder:\n",
    "    df.to_csv(path+number_person_as_string+'\\\\full.csv', index=False)\n",
    "    \n",
    "def delete_redundant_rows(df):\n",
    "    '''Deletes rows for which both the longitude and latitude did not change\n",
    "    Seems like there are no such rows now??? I was sure I saw them!'''\n",
    "    \n",
    "    for i in range(df.shape[0]-1):\n",
    "        to_be_deleted_rows = []\n",
    "        if df.loc[i]['latitude'] == df.loc[i+1]['latitude'] and df.loc[i]['longitude'] == df.loc[i+1]['longitude']:\n",
    "            to_be_deleted_rows.append(i+1)\n",
    "            \n",
    "    return to_be_deleted_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e730660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>altitude</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.984683</td>\n",
       "      <td>116.318450</td>\n",
       "      <td>150</td>\n",
       "      <td>2008-10-23 10:53:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.984686</td>\n",
       "      <td>116.318417</td>\n",
       "      <td>150</td>\n",
       "      <td>2008-10-23 10:53:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.984688</td>\n",
       "      <td>116.318385</td>\n",
       "      <td>150</td>\n",
       "      <td>2008-10-23 10:53:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.984655</td>\n",
       "      <td>116.318263</td>\n",
       "      <td>150</td>\n",
       "      <td>2008-10-23 10:53:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.984611</td>\n",
       "      <td>116.318026</td>\n",
       "      <td>150</td>\n",
       "      <td>2008-10-23 10:53:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude   longitude  altitude                date\n",
       "0  39.984683  116.318450       150 2008-10-23 10:53:10\n",
       "1  39.984686  116.318417       150 2008-10-23 10:53:15\n",
       "2  39.984688  116.318385       150 2008-10-23 10:53:20\n",
       "3  39.984655  116.318263       150 2008-10-23 10:53:25\n",
       "4  39.984611  116.318026       150 2008-10-23 10:53:30"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data_per_file(path=f\"{path}000\\\\Trajectory\\\\20081023025304.plt\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "583dd443",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_per_person(path, \"000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2ed3067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " '001',\n",
       " '002',\n",
       " '003',\n",
       " '004',\n",
       " '005',\n",
       " '006',\n",
       " '007',\n",
       " '008',\n",
       " '009',\n",
       " '010',\n",
       " '011',\n",
       " '012',\n",
       " '013',\n",
       " '014',\n",
       " '015',\n",
       " '016',\n",
       " '017',\n",
       " '018',\n",
       " '019',\n",
       " '020',\n",
       " '021',\n",
       " '022',\n",
       " '023',\n",
       " '024',\n",
       " '025',\n",
       " '026',\n",
       " '027',\n",
       " '028',\n",
       " '029',\n",
       " '030',\n",
       " '031',\n",
       " '032',\n",
       " '033',\n",
       " '034',\n",
       " '035',\n",
       " '036',\n",
       " '037',\n",
       " '038',\n",
       " '039',\n",
       " '040',\n",
       " '041',\n",
       " '042',\n",
       " '043',\n",
       " '044',\n",
       " '045',\n",
       " '046',\n",
       " '047',\n",
       " '048',\n",
       " '049',\n",
       " '050',\n",
       " '051',\n",
       " '052',\n",
       " '053',\n",
       " '054',\n",
       " '055',\n",
       " '056',\n",
       " '057',\n",
       " '058',\n",
       " '059',\n",
       " '060',\n",
       " '061',\n",
       " '062',\n",
       " '063',\n",
       " '064',\n",
       " '065',\n",
       " '066',\n",
       " '067',\n",
       " '068',\n",
       " '069',\n",
       " '070',\n",
       " '071',\n",
       " '072',\n",
       " '073',\n",
       " '074',\n",
       " '075',\n",
       " '076',\n",
       " '077',\n",
       " '078',\n",
       " '079',\n",
       " '080',\n",
       " '081',\n",
       " '082',\n",
       " '083',\n",
       " '084',\n",
       " '085',\n",
       " '086',\n",
       " '087',\n",
       " '088',\n",
       " '089',\n",
       " '090',\n",
       " '091',\n",
       " '092',\n",
       " '093',\n",
       " '094',\n",
       " '095',\n",
       " '096',\n",
       " '097',\n",
       " '098',\n",
       " '099',\n",
       " '100',\n",
       " '101',\n",
       " '102',\n",
       " '103',\n",
       " '104',\n",
       " '105',\n",
       " '106',\n",
       " '107',\n",
       " '108',\n",
       " '109',\n",
       " '110',\n",
       " '111',\n",
       " '112',\n",
       " '113',\n",
       " '114',\n",
       " '115',\n",
       " '116',\n",
       " '117',\n",
       " '118',\n",
       " '119',\n",
       " '120',\n",
       " '121',\n",
       " '122',\n",
       " '123',\n",
       " '124',\n",
       " '125',\n",
       " '126',\n",
       " '127',\n",
       " '128',\n",
       " '129',\n",
       " '130',\n",
       " '131',\n",
       " '132',\n",
       " '133',\n",
       " '134',\n",
       " '135',\n",
       " '136',\n",
       " '137',\n",
       " '138',\n",
       " '139',\n",
       " '140',\n",
       " '141',\n",
       " '142',\n",
       " '143',\n",
       " '144',\n",
       " '145',\n",
       " '146',\n",
       " '147',\n",
       " '148',\n",
       " '149',\n",
       " '150',\n",
       " '151',\n",
       " '152',\n",
       " '153',\n",
       " '154',\n",
       " '155',\n",
       " '156',\n",
       " '157',\n",
       " '158',\n",
       " '159',\n",
       " '160',\n",
       " '161',\n",
       " '162',\n",
       " '163',\n",
       " '164',\n",
       " '165',\n",
       " '166',\n",
       " '167',\n",
       " '168',\n",
       " '169',\n",
       " '170',\n",
       " '171',\n",
       " '172',\n",
       " '173',\n",
       " '174',\n",
       " '175',\n",
       " '176',\n",
       " '177',\n",
       " '178',\n",
       " '179',\n",
       " '180',\n",
       " '181']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Warning: Takes quite a while\n",
    "if False\n",
    "    for user in os.listdir(path):\n",
    "        save_data_per_person(path, user)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
